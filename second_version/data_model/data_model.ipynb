{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression, LogisticRegressionCV, Lasso, LassoCV, Ridge"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_nyc_files = []\n",
    "all_sao_files = []\n",
    "\n",
    "def get_files(destination: str=\"nyc\", file_names: list = all_nyc_files) -> list:\n",
    "    \"\"\"\n",
    "    This function retrieves the names of all .csv files in a specified directory.\n",
    "\n",
    "    Args:\n",
    "    -----\n",
    "    destination (str): The destination city for which to retrieve the file names. \n",
    "    (Default sets to \"nyc\")\n",
    "    \n",
    "    file_names (list): The list to populate with the file names. \n",
    "    (Default sets to all_nyc_files)\n",
    "    \n",
    "    Return:\n",
    "    -------\n",
    "    list: A list of file names for all .csv files in the specified directory.\n",
    "    \"\"\"\n",
    "\n",
    "    file_path = f'..\\\\webscraping\\\\bxl_to_{destination}'\n",
    "\n",
    "    for file_name in os.listdir(file_path):\n",
    "        # Split the file name into a base name and an extension\n",
    "        base_name, extension = os.path.splitext(file_name)\n",
    "        \n",
    "        # Check if the file has a .csv extension\n",
    "        if extension == '.csv':\n",
    "            # Append the file name to the list\n",
    "            file_names.append(file_name)\n",
    "        \n",
    "    return(file_names)\n",
    " \n",
    "all_nyc_files = get_files()\n",
    "all_sao_files = get_files(destination=\"sao\", file_names=all_sao_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv_files(destination: str = \"nyc\", file_names: list[str] = all_nyc_files, result = None):\n",
    "    \"\"\"\n",
    "    This function concatenates multiple CSV files into a single DataFrame. \n",
    "    If the result is None, it creates a list of DataFrames from the CSV files and concatenates them. \n",
    "    If the result is not None, it appends the DataFrames from the CSV files to the result.\n",
    "\n",
    "    Args:\n",
    "    -----\n",
    "    result : The DataFrame to append the data to. If None, a new DataFrame is created.\n",
    " \n",
    "    dates (list): The list of dates to use for the filenames of the CSV files.\n",
    "    \n",
    "    destination (str): The destination to use for the filenames of the CSV files.\n",
    " \n",
    "    Return:\n",
    "    -------\n",
    "    DataFrame: The concatenated DataFrame.\n",
    "    \"\"\"\n",
    "    if result is None:\n",
    "        dfs = []\n",
    "        for name in file_names:\n",
    "            file_path = f\"..\\\\webscraping\\\\bxl_to_{destination}\\\\{name}\"\n",
    "            df = pd.read_csv(file_path)\n",
    "            dfs.append(df)\n",
    "        result = pd.concat(dfs, axis=0, ignore_index=True)\n",
    "    else:\n",
    "        for name in file_names:\n",
    "            filename = f\"..\\\\webscraping\\\\bxl_to_{destination}\\\\booking_{name}.csv\"\n",
    "            df = pd.read_csv(filename)\n",
    "            result = pd.concat([result, df], axis=0, ignore_index=True)\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_time(time):\n",
    "    hour = int(time.split(':')[0])\n",
    "    if 0 <= hour < 12:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transfomed_df(df):\n",
    "    \"\"\"\n",
    "    This function transforms a DataFrame by splitting and renaming columns, \n",
    "    converting data types, and applying functions to columns.\n",
    "\n",
    "    Args:\n",
    "    -----\n",
    "    df : The DataFrame to transform.\n",
    " \n",
    "    Return:\n",
    "    -------\n",
    "    DataFrame: The transformed DataFrame.\n",
    "    \"\"\"\n",
    "\n",
    "    air_cols = [col for col in df.columns if col.endswith('_airline_company')]\n",
    "    df[air_cols] = df[air_cols].astype(str)\n",
    "    df[air_cols] = df[air_cols].apply(lambda x: x.str.split(\",\").str[0])\n",
    "    \n",
    "    df['out_stop_num'] = df['out_stop_num'].str.split(' ').str[0]\n",
    "    df['in_stop_num'] = df['in_stop_num'].str.split(' ').str[0]\n",
    "    df['out_stop_num'] = df['out_stop_num'].astype(float)\n",
    "    df['in_stop_num'] = df['in_stop_num'].astype(float)\n",
    "\n",
    "    df[\"tot_stop\"] = df['out_stop_num'] + df['in_stop_num']\n",
    "\n",
    "\n",
    "    split_df = df.pop('price_ticket').str.rsplit(' ', n=1, expand=True).rename(columns={0: 'ticket_price', 1: 'currency'})\n",
    "    df = df.join(split_df)\n",
    "    df['ticket_price'] = df['ticket_price'].str.replace(',', '.').str.replace(' ', '').astype(float)\n",
    "\n",
    "    date_cols = [col for col in df.columns if col.endswith('_date')]\n",
    "    year= '2023'\n",
    "    for col in date_cols:\n",
    "        df[col] = pd.to_datetime(df[col] + ' ' + year, format='%b %d %Y')\n",
    "    \n",
    "    time_cols = [col for col in df.columns if col.endswith('_time')]\n",
    "    df[time_cols] = df[time_cols].apply(lambda x: pd.to_datetime(x, format='%I:%M %p').dt.strftime('%H:%M'))\n",
    "\n",
    "    duration_cols = [col for col in df.columns if col.endswith('_duration')]\n",
    "    df[duration_cols] = df[duration_cols].applymap(lambda x: pd.to_timedelta(x.replace('h', ' hours ').replace('m', ' min')))\n",
    "\n",
    "    df['tot_duration'] = df[\"out_duration\"] + df[\"in_duration\"]\n",
    "    df['tot_duration_seconds'] = df['tot_duration'].dt.total_seconds()\n",
    "    \n",
    "    \n",
    "    df[\"airline_company\"] = df[\"out_airline_company\"]\n",
    "    df['airline_company_dummy'] = (df['airline_company'] == 'Swiss').astype(int)\n",
    "\n",
    "    df['destination_dummy'] = (df['arr_city'] == 'JFK').astype(int)\n",
    "\n",
    "    for col in ['out_dep_time', 'out_arr_time', 'in_dep_time', 'in_arr_time']:\n",
    "        df[col + '_dummy'] = df[col].apply(convert_time)\n",
    "\n",
    "    cur_time = datetime.datetime.now()\n",
    "    year = cur_time.strftime('%Y')\n",
    "    month = cur_time.strftime('%b')\n",
    "    \n",
    "    # Construct a date string for each row\n",
    "    df['date'] = df['day_scrap'].apply(lambda x: f'{year}-{month}-{x:02d}')\n",
    "\n",
    "    # Convert the date column to a datetime object\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "    # Extract the day of the week\n",
    "    df['day_of_week'] = df['date'].dt.day_name()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the dataframe for nyc\n",
    "df1 = read_csv_files()\n",
    "df1 = transfomed_df(df1)\n",
    "df1 = df1.dropna()\n",
    "df1 = df1.reset_index(drop=True)\n",
    "\n",
    "# Get the dataframe for sao\n",
    "df2 = read_csv_files(destination=\"sao\", file_names=all_sao_files)\n",
    "df2 = transfomed_df(df2)\n",
    "df2 = df2.dropna()\n",
    "df2 = df2.reset_index(drop=True)\n",
    "\n",
    "# merge dataframe\n",
    "df = pd.concat([df1, df2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>out_airline_company</th>\n",
       "      <th>in_airline_company</th>\n",
       "      <th>dep_city</th>\n",
       "      <th>arr_city</th>\n",
       "      <th>out_dep_date</th>\n",
       "      <th>out_dep_time</th>\n",
       "      <th>out_duration</th>\n",
       "      <th>out_stop_num</th>\n",
       "      <th>out_arr_date</th>\n",
       "      <th>out_arr_time</th>\n",
       "      <th>...</th>\n",
       "      <th>tot_duration_seconds</th>\n",
       "      <th>airline_company</th>\n",
       "      <th>airline_company_dummy</th>\n",
       "      <th>destination_dummy</th>\n",
       "      <th>out_dep_time_dummy</th>\n",
       "      <th>out_arr_time_dummy</th>\n",
       "      <th>in_dep_time_dummy</th>\n",
       "      <th>in_arr_time_dummy</th>\n",
       "      <th>date</th>\n",
       "      <th>day_of_week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lufthansa</td>\n",
       "      <td>Lufthansa</td>\n",
       "      <td>BRU</td>\n",
       "      <td>JFK</td>\n",
       "      <td>2023-08-01</td>\n",
       "      <td>09:35</td>\n",
       "      <td>0 days 11:25:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2023-08-01</td>\n",
       "      <td>15:00</td>\n",
       "      <td>...</td>\n",
       "      <td>75900.0</td>\n",
       "      <td>Lufthansa</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-05-20</td>\n",
       "      <td>Saturday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lufthansa</td>\n",
       "      <td>Lufthansa</td>\n",
       "      <td>BRU</td>\n",
       "      <td>JFK</td>\n",
       "      <td>2023-08-01</td>\n",
       "      <td>13:15</td>\n",
       "      <td>0 days 12:50:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2023-08-01</td>\n",
       "      <td>20:05</td>\n",
       "      <td>...</td>\n",
       "      <td>105000.0</td>\n",
       "      <td>Lufthansa</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-05-20</td>\n",
       "      <td>Saturday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lufthansa</td>\n",
       "      <td>Lufthansa</td>\n",
       "      <td>BRU</td>\n",
       "      <td>JFK</td>\n",
       "      <td>2023-08-01</td>\n",
       "      <td>08:50</td>\n",
       "      <td>0 days 12:10:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2023-08-01</td>\n",
       "      <td>15:00</td>\n",
       "      <td>...</td>\n",
       "      <td>78600.0</td>\n",
       "      <td>Lufthansa</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-05-20</td>\n",
       "      <td>Saturday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lufthansa</td>\n",
       "      <td>Lufthansa</td>\n",
       "      <td>BRU</td>\n",
       "      <td>JFK</td>\n",
       "      <td>2023-08-01</td>\n",
       "      <td>09:35</td>\n",
       "      <td>0 days 11:25:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2023-08-01</td>\n",
       "      <td>15:00</td>\n",
       "      <td>...</td>\n",
       "      <td>79500.0</td>\n",
       "      <td>Lufthansa</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-05-20</td>\n",
       "      <td>Saturday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lufthansa</td>\n",
       "      <td>Lufthansa</td>\n",
       "      <td>BRU</td>\n",
       "      <td>JFK</td>\n",
       "      <td>2023-08-01</td>\n",
       "      <td>09:35</td>\n",
       "      <td>0 days 11:25:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2023-08-01</td>\n",
       "      <td>15:00</td>\n",
       "      <td>...</td>\n",
       "      <td>80100.0</td>\n",
       "      <td>Lufthansa</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-05-20</td>\n",
       "      <td>Saturday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2533</th>\n",
       "      <td>Swiss</td>\n",
       "      <td>Swiss</td>\n",
       "      <td>BRU</td>\n",
       "      <td>GRU</td>\n",
       "      <td>2023-08-01</td>\n",
       "      <td>15:00</td>\n",
       "      <td>0 days 19:25:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2023-08-02</td>\n",
       "      <td>05:25</td>\n",
       "      <td>...</td>\n",
       "      <td>151800.0</td>\n",
       "      <td>Swiss</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-05-26</td>\n",
       "      <td>Friday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2534</th>\n",
       "      <td>Swiss</td>\n",
       "      <td>Swiss</td>\n",
       "      <td>BRU</td>\n",
       "      <td>GRU</td>\n",
       "      <td>2023-08-01</td>\n",
       "      <td>06:55</td>\n",
       "      <td>1 days 03:30:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2023-08-02</td>\n",
       "      <td>05:25</td>\n",
       "      <td>...</td>\n",
       "      <td>170100.0</td>\n",
       "      <td>Swiss</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-05-26</td>\n",
       "      <td>Friday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2535</th>\n",
       "      <td>Swiss</td>\n",
       "      <td>Swiss</td>\n",
       "      <td>BRU</td>\n",
       "      <td>GRU</td>\n",
       "      <td>2023-08-01</td>\n",
       "      <td>09:45</td>\n",
       "      <td>1 days 00:40:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2023-08-02</td>\n",
       "      <td>05:25</td>\n",
       "      <td>...</td>\n",
       "      <td>207600.0</td>\n",
       "      <td>Swiss</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-05-26</td>\n",
       "      <td>Friday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2536</th>\n",
       "      <td>Swiss</td>\n",
       "      <td>Swiss</td>\n",
       "      <td>BRU</td>\n",
       "      <td>GRU</td>\n",
       "      <td>2023-08-01</td>\n",
       "      <td>09:45</td>\n",
       "      <td>1 days 00:40:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2023-08-02</td>\n",
       "      <td>05:25</td>\n",
       "      <td>...</td>\n",
       "      <td>213000.0</td>\n",
       "      <td>Swiss</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-05-26</td>\n",
       "      <td>Friday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2537</th>\n",
       "      <td>Swiss</td>\n",
       "      <td>Swiss</td>\n",
       "      <td>BRU</td>\n",
       "      <td>GRU</td>\n",
       "      <td>2023-08-01</td>\n",
       "      <td>06:55</td>\n",
       "      <td>1 days 03:30:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2023-08-02</td>\n",
       "      <td>05:25</td>\n",
       "      <td>...</td>\n",
       "      <td>217800.0</td>\n",
       "      <td>Swiss</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-05-26</td>\n",
       "      <td>Friday</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5462 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     out_airline_company in_airline_company dep_city arr_city out_dep_date  \\\n",
       "0              Lufthansa          Lufthansa      BRU      JFK   2023-08-01   \n",
       "1              Lufthansa          Lufthansa      BRU      JFK   2023-08-01   \n",
       "2              Lufthansa          Lufthansa      BRU      JFK   2023-08-01   \n",
       "3              Lufthansa          Lufthansa      BRU      JFK   2023-08-01   \n",
       "4              Lufthansa          Lufthansa      BRU      JFK   2023-08-01   \n",
       "...                  ...                ...      ...      ...          ...   \n",
       "2533               Swiss              Swiss      BRU      GRU   2023-08-01   \n",
       "2534               Swiss              Swiss      BRU      GRU   2023-08-01   \n",
       "2535               Swiss              Swiss      BRU      GRU   2023-08-01   \n",
       "2536               Swiss              Swiss      BRU      GRU   2023-08-01   \n",
       "2537               Swiss              Swiss      BRU      GRU   2023-08-01   \n",
       "\n",
       "     out_dep_time    out_duration  out_stop_num out_arr_date out_arr_time  \\\n",
       "0           09:35 0 days 11:25:00           1.0   2023-08-01        15:00   \n",
       "1           13:15 0 days 12:50:00           1.0   2023-08-01        20:05   \n",
       "2           08:50 0 days 12:10:00           1.0   2023-08-01        15:00   \n",
       "3           09:35 0 days 11:25:00           1.0   2023-08-01        15:00   \n",
       "4           09:35 0 days 11:25:00           1.0   2023-08-01        15:00   \n",
       "...           ...             ...           ...          ...          ...   \n",
       "2533        15:00 0 days 19:25:00           1.0   2023-08-02        05:25   \n",
       "2534        06:55 1 days 03:30:00           1.0   2023-08-02        05:25   \n",
       "2535        09:45 1 days 00:40:00           1.0   2023-08-02        05:25   \n",
       "2536        09:45 1 days 00:40:00           1.0   2023-08-02        05:25   \n",
       "2537        06:55 1 days 03:30:00           1.0   2023-08-02        05:25   \n",
       "\n",
       "      ... tot_duration_seconds airline_company airline_company_dummy  \\\n",
       "0     ...              75900.0       Lufthansa                     0   \n",
       "1     ...             105000.0       Lufthansa                     0   \n",
       "2     ...              78600.0       Lufthansa                     0   \n",
       "3     ...              79500.0       Lufthansa                     0   \n",
       "4     ...              80100.0       Lufthansa                     0   \n",
       "...   ...                  ...             ...                   ...   \n",
       "2533  ...             151800.0           Swiss                     1   \n",
       "2534  ...             170100.0           Swiss                     1   \n",
       "2535  ...             207600.0           Swiss                     1   \n",
       "2536  ...             213000.0           Swiss                     1   \n",
       "2537  ...             217800.0           Swiss                     1   \n",
       "\n",
       "      destination_dummy out_dep_time_dummy out_arr_time_dummy  \\\n",
       "0                     1                  0                  1   \n",
       "1                     1                  1                  1   \n",
       "2                     1                  0                  1   \n",
       "3                     1                  0                  1   \n",
       "4                     1                  0                  1   \n",
       "...                 ...                ...                ...   \n",
       "2533                  0                  1                  0   \n",
       "2534                  0                  0                  0   \n",
       "2535                  0                  0                  0   \n",
       "2536                  0                  0                  0   \n",
       "2537                  0                  0                  0   \n",
       "\n",
       "      in_dep_time_dummy  in_arr_time_dummy       date  day_of_week  \n",
       "0                     1                  0 2023-05-20     Saturday  \n",
       "1                     1                  1 2023-05-20     Saturday  \n",
       "2                     1                  0 2023-05-20     Saturday  \n",
       "3                     1                  0 2023-05-20     Saturday  \n",
       "4                     1                  0 2023-05-20     Saturday  \n",
       "...                 ...                ...        ...          ...  \n",
       "2533                  1                  1 2023-05-26       Friday  \n",
       "2534                  1                  1 2023-05-26       Friday  \n",
       "2535                  1                  0 2023-05-26       Friday  \n",
       "2536                  1                  0 2023-05-26       Friday  \n",
       "2537                  1                  0 2023-05-26       Friday  \n",
       "\n",
       "[5462 rows x 32 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create scatter plots of ticket_price against each independent variable\n",
    "def scatter_plot(df = df1):\n",
    "    fig, axs = plt.subplots(2, 3, figsize=(15, 10))\n",
    "    axs[0, 0].scatter(df['tot_duration'].dt.total_seconds(), df['ticket_price'])\n",
    "    axs[0, 0].set_xlabel('tot_duration')\n",
    "    axs[0, 0].set_ylabel('ticket_price')\n",
    "    axs[0, 1].scatter(df['hour_scrap'], df['ticket_price'])\n",
    "    axs[0, 1].set_xlabel('hour_scrap')\n",
    "    axs[0, 1].set_ylabel('ticket_price')\n",
    "    axs[0, 2].scatter(df['day_scrap'], df['ticket_price'])\n",
    "    axs[0, 2].set_xlabel('day_scrap')\n",
    "    axs[0, 2].set_ylabel('ticket_price')\n",
    "    axs[1, 0].scatter(df['tot_stop'], df['ticket_price'])\n",
    "    axs[1, 0].set_xlabel('tot_stop')\n",
    "    axs[1, 0].set_ylabel('ticket_price')\n",
    "    axs[1, 1].scatter(df['airline_company_dummy'], df['ticket_price'])\n",
    "    axs[1, 1].set_xlabel('airline_company_dummy')\n",
    "    axs[1, 1].set_ylabel('ticket_price')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.66\n"
     ]
    }
   ],
   "source": [
    "# select the independent and dependent variables\n",
    "X = df[['tot_duration_seconds', 'hour_scrap', 'hour_scrap','ticket_price','destination_dummy', 'out_dep_time_dummy', 'in_dep_time_dummy', 'out_dep_time_dummy', 'in_arr_time_dummy']]\n",
    "y = df['airline_company_dummy']\n",
    "\n",
    "# X = df1[['tot_duration_seconds', 'airline_company_dummy']]\n",
    "# y = df1['ticket_price']\n",
    "\n",
    "\n",
    "# split the data into a training set and a test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# create and fit the model using the training data\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# make predictions on the test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# calculate the accuracy of the predictions\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f'Accuracy: {accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best C: 0.05\n",
      "Accuracy: 0.67\n"
     ]
    }
   ],
   "source": [
    "# create and fit the model using the training data\n",
    "model = LogisticRegressionCV()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# print the best C value found by cross-validation\n",
    "print(f'Best C: {model.C_[0]:.2f}')\n",
    "\n",
    "# make predictions on the test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# calculate the accuracy of the predictions\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f'Accuracy: {accuracy:.2f}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the independent and dependent variables\n",
    "\n",
    "# Entire Dataframes for both destinations\n",
    "X_1 = df[['tot_duration_seconds', 'hour_scrap', 'day_scrap','airline_company_dummy', 'destination_dummy','out_dep_time_dummy', 'out_arr_time_dummy', 'in_dep_time_dummy', 'in_arr_time_dummy']]\n",
    "y_1 = df['ticket_price']\n",
    "\n",
    "# Dataframe for the destination nyc only\n",
    "X_2 = df1[['tot_duration_seconds', 'hour_scrap', 'day_scrap','airline_company_dummy', 'destination_dummy','out_dep_time_dummy', 'out_arr_time_dummy', 'in_dep_time_dummy', 'in_arr_time_dummy']]\n",
    "y_2 = df1['ticket_price']\n",
    "\n",
    "# Dataframe for the destination sao only\n",
    "X_3 = df2[['tot_duration_seconds', 'hour_scrap', 'day_scrap','airline_company_dummy', 'destination_dummy','out_dep_time_dummy', 'out_arr_time_dummy', 'in_dep_time_dummy', 'in_arr_time_dummy']]\n",
    "y_3 = df2['ticket_price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lin_reg(X=X_1, y=y_1, model=LinearRegression()):\n",
    "    # split the data into a training set and a test set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    model1 = model\n",
    "    model1.fit(X_train, y_train)\n",
    "\n",
    "    # Calculate the training error\n",
    "    y_train_pred = model1.predict(X_train)\n",
    "    train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "    train_rmse = np.sqrt(train_mse)\n",
    "\n",
    "    # Calculate the test error\n",
    "    y_test_pred = model1.predict(X_test)\n",
    "    test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "    test_rmse = np.sqrt(test_mse)\n",
    "\n",
    "    # Perform 10-fold cross-validation\n",
    "    scores = cross_val_score(model1, X_train, y_train, scoring='neg_mean_squared_error', cv=10)\n",
    "    rmse_scores = np.sqrt(-scores)\n",
    "\n",
    "    # Calculate the training error\n",
    "    y_train_pred = model1.predict(X_train)\n",
    "    train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "    train_rmse = np.sqrt(train_mse)\n",
    "\n",
    "    # Calculate the test error\n",
    "    y_test_pred = model1.predict(X_test)\n",
    "    test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "    test_rmse = np.sqrt(test_mse)\n",
    "\n",
    "    # Perform 10-fold cross-validation\n",
    "    scores = cross_val_score(model1, X_train, y_train, scoring='neg_mean_squared_error', cv=10)\n",
    "    rmse_scores = np.sqrt(-scores)\n",
    "\n",
    "    # Calculate the mean cross-validation RMSE\n",
    "    cv_rmse = rmse_scores.mean()\n",
    "\n",
    "    # Make predictions on the test data\n",
    "    y_test_pred = model1.predict(X_test)\n",
    "\n",
    "    # Calculate the evaluation metrics\n",
    "    mae = mean_absolute_error(y_test, y_test_pred)\n",
    "    mse = mean_squared_error(y_test, y_test_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_test, y_test_pred)\n",
    "\n",
    "\n",
    "    # Display the results\n",
    "    print(model1.coef_, model1.intercept_)\n",
    "    print(f'Training RMSE: {train_rmse:.2f}')\n",
    "    print(f'Test RMSE: {test_rmse:.2f}')\n",
    "    print(f'Scores: {rmse_scores}')\n",
    "    print(f'Mean: {rmse_scores.mean():.2f}')\n",
    "    print(f'Standard deviation: {rmse_scores.std():.2f}')\n",
    "    print(f'Cross-validation RMSE: {cv_rmse:.2f}')\n",
    "    print(f'Mean Absolute Error: {mae:.2f}')\n",
    "    print(f'Mean Squared Error: {mse:.2f}')\n",
    "    print(f'Root Mean Squared Error: {rmse:.2f}')\n",
    "    print(f'R-squared: {r2:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.83456978e-03  2.14296528e+00  2.33989291e+01 -1.87828436e+02\n",
      " -5.39446066e+02 -1.87733729e+01 -5.39446066e+02  0.00000000e+00\n",
      "  3.39791406e+01] 1824.7779120333637\n",
      "Training RMSE: 163.96\n",
      "Test RMSE: 140.31\n",
      "Scores: [148.96615612 129.41914973 132.30699195 130.41623573 326.29864362\n",
      " 138.70349383 131.97505416 130.9700382  124.34730452 143.50254667]\n",
      "Mean: 153.69\n",
      "Standard deviation: 57.95\n",
      "Cross-validation RMSE: 153.69\n",
      "Mean Absolute Error: 106.56\n",
      "Mean Squared Error: 19686.02\n",
      "Root Mean Squared Error: 140.31\n",
      "R-squared: 0.93\n"
     ]
    }
   ],
   "source": [
    "lin_reg()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on these results, it appears that the model is performing well on the training data, with a training RMSE of 163.96 and an R-squared value of 0.93. This indicates that it is able to explain 93% of the variance in the target variable on the training data.\n",
    "\n",
    "The test RMSE is lower than the training RMSE, which suggests that the model is generalizing well to new data. However, the mean cross-validation RMSE is higher than both the training and test RMSE. This may indicate that there is some variation in the model’s performance between different folds of the cross-validation.\n",
    "\n",
    "The coefficients of the model show the relationship between each feature and the target variable. For example, the coefficient for tot_duration_seconds is -1.83e-03, which indicates that an increase in tot_duration_seconds is associated with a small decrease in the target variable.\n",
    "\n",
    "The intercept of the model is 1824.78, which represents the expected value of the target variable when all the features are equal to zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.99089026e-03  1.25479607e+00 -1.93410446e+00 -1.78618958e+02\n",
      "  2.84217094e-14 -2.18190826e+01  0.00000000e+00  0.00000000e+00\n",
      " -2.64874102e+00] 1370.5350570598239\n",
      "Training RMSE: 123.12\n",
      "Test RMSE: 290.41\n",
      "Scores: [ 98.4582475  126.60545646 138.77880791  99.80517037 114.40349916\n",
      " 127.89087879 124.26464074 120.53237444 107.56778823 164.34506248]\n",
      "Mean: 122.27\n",
      "Standard deviation: 18.57\n",
      "Cross-validation RMSE: 122.27\n",
      "Mean Absolute Error: 99.68\n",
      "Mean Squared Error: 84336.13\n",
      "Root Mean Squared Error: 290.41\n",
      "R-squared: 0.20\n"
     ]
    }
   ],
   "source": [
    "lin_reg(X = X_2, y=y_2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on these results, it appears that the model is performing well on the training data, with a training RMSE of 123.12 and an R-squared value of 0.20. This indicates that the model is able to explain 20% of the variance in the target variable on the training data.\n",
    "\n",
    "However, the test RMSE is much higher than the training RMSE and the mean cross-validation RMSE. This may indicate that the model is not performing as well on the test data as it is on the training data.\n",
    "\n",
    "The coefficients of the model show the relationship between each feature and the target variable. For example, the coefficient for tot_duration_seconds is -1.99e-03, which indicates that an increase in tot_duration_seconds is associated with a small decrease in the target variable.\n",
    "\n",
    "The intercept of the model is 1370.54, which represents the expected value of the target variable when all the features are equal to zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 8.16357693e-04  2.07743355e+00  4.15124002e+01 -2.43035388e+02\n",
      "  2.84217094e-14  2.15955336e+01  0.00000000e+00  0.00000000e+00\n",
      "  2.35889859e+02] 871.2525092790693\n",
      "Training RMSE: 126.27\n",
      "Test RMSE: 131.97\n",
      "Scores: [127.53950206 122.34999662 120.78317196 132.49645005 132.69015395\n",
      " 126.76369706 124.00436748 140.37168376 126.12422556 111.94656897]\n",
      "Mean: 126.51\n",
      "Standard deviation: 7.32\n",
      "Cross-validation RMSE: 126.51\n",
      "Mean Absolute Error: 102.43\n",
      "Mean Squared Error: 17417.22\n",
      "Root Mean Squared Error: 131.97\n",
      "R-squared: 0.56\n"
     ]
    }
   ],
   "source": [
    "lin_reg(X=X_3, y=y_3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the results, it appears that the model is performing well on both the training and test data. The training and test RMSE are similar, and the R-squared value is 0.56, indicating that the model is able to explain 56% of the variance in the target variable.\n",
    "\n",
    "The mean cross-validation RMSE is also similar to the training and test RMSE, which suggests that the model is generalizing well to new data.\n",
    "\n",
    "The intercept of the model is 871.25, which represents the expected value of the target variable when all the features are equal to zero."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. The clean version"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modification of the previous model by removing 2 independent variables (out_arr_time_dummy and in_dep_time_dummy ). The same interpretations can be said here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_4 = df[['tot_duration_seconds', 'hour_scrap', 'day_scrap','airline_company_dummy', 'destination_dummy','out_dep_time_dummy', 'in_arr_time_dummy']]\n",
    "y_4 = df['ticket_price']\n",
    "\n",
    "X_5 = df1[['tot_duration_seconds', 'hour_scrap', 'day_scrap','airline_company_dummy', 'destination_dummy','out_dep_time_dummy', 'in_arr_time_dummy']]\n",
    "y_5 = df1['ticket_price']\n",
    "\n",
    "X_6 = df2[['tot_duration_seconds', 'hour_scrap', 'day_scrap','airline_company_dummy', 'destination_dummy','out_dep_time_dummy', 'in_arr_time_dummy']]\n",
    "y_6 = df2['ticket_price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.83456978e-03  2.14296528e+00  2.33989291e+01 -1.87828436e+02\n",
      " -1.07889213e+03 -1.87733729e+01  3.39791406e+01] 1824.7779121370688\n",
      "Training RMSE: 163.96\n",
      "Test RMSE: 140.31\n",
      "Scores: [148.96615612 129.41914973 132.30699195 130.41623573 326.29864361\n",
      " 138.70349383 131.97505416 130.9700382  124.34730452 143.50254667]\n",
      "Mean: 153.69\n",
      "Standard deviation: 57.95\n",
      "Cross-validation RMSE: 153.69\n",
      "Mean Absolute Error: 106.56\n",
      "Mean Squared Error: 19686.02\n",
      "Root Mean Squared Error: 140.31\n",
      "R-squared: 0.93\n"
     ]
    }
   ],
   "source": [
    "lin_reg(X=X_4, y=y_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.99089026e-03  1.25479607e+00 -1.93410446e+00 -1.78618958e+02\n",
      "  0.00000000e+00 -2.18190826e+01 -2.64874102e+00] 1370.5350570598252\n",
      "Training RMSE: 123.12\n",
      "Test RMSE: 290.41\n",
      "Scores: [ 98.4582475  126.60545646 138.77880791  99.80517037 114.40349916\n",
      " 127.89087879 124.26464074 120.53237444 107.56778823 164.34506248]\n",
      "Mean: 122.27\n",
      "Standard deviation: 18.57\n",
      "Cross-validation RMSE: 122.27\n",
      "Mean Absolute Error: 99.68\n",
      "Mean Squared Error: 84336.13\n",
      "Root Mean Squared Error: 290.41\n",
      "R-squared: 0.20\n"
     ]
    }
   ],
   "source": [
    "lin_reg(X=X_5, y=y_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 8.16357693e-04  2.07743355e+00  4.15124002e+01 -2.43035388e+02\n",
      "  1.13686838e-13  2.15955336e+01  2.35889859e+02] 871.2525092790704\n",
      "Training RMSE: 126.27\n",
      "Test RMSE: 131.97\n",
      "Scores: [127.53950206 122.34999662 120.78317196 132.49645005 132.69015395\n",
      " 126.76369706 124.00436748 140.37168376 126.12422556 111.94656897]\n",
      "Mean: 126.51\n",
      "Standard deviation: 7.32\n",
      "Cross-validation RMSE: 126.51\n",
      "Mean Absolute Error: 102.43\n",
      "Mean Squared Error: 17417.22\n",
      "Root Mean Squared Error: 131.97\n",
      "R-squared: 0.56\n"
     ]
    }
   ],
   "source": [
    "lin_reg(X=X_6, y=y_6)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Different X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The lowest predicted ticket price is on Tuesday at hour 8.\n"
     ]
    }
   ],
   "source": [
    "df_test = df[['ticket_price','day_of_week', 'hour_scrap']]\n",
    "\n",
    "# One-hot encode the day_of_week column\n",
    "df_encoded = pd.get_dummies(df_test, columns=['day_of_week'])\n",
    "\n",
    "# Select the independent and dependent variables\n",
    "X = df_encoded.drop('ticket_price', axis=1)\n",
    "y = df_encoded['ticket_price']\n",
    "\n",
    "# Create a Linear Regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Fit the model to the data\n",
    "model.fit(X, y)\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(X)\n",
    "\n",
    "# Get all unique values in the day_of_week column\n",
    "days = df['day_of_week'].unique()\n",
    "\n",
    "# Create an array of all possible combinations of days and hours\n",
    "hours = np.arange(8, 22, 2)\n",
    "X_new = pd.DataFrame(np.array(np.meshgrid(days, hours)).T.reshape(-1, 2), columns=['day_of_week', 'hour_scrap'])\n",
    "\n",
    "# Save a copy of X_new before one-hot encoding\n",
    "X_new_original = X_new.copy()\n",
    "\n",
    "# One-hot encode the day_of_week column in X_new\n",
    "X_new = pd.get_dummies(X_new, columns=['day_of_week'])\n",
    "\n",
    "# Make predictions for all combinations\n",
    "predictions_new = model.predict(X_new)\n",
    "\n",
    "# Find the index of the minimum predicted price\n",
    "min_index = np.argmin(predictions_new)\n",
    "\n",
    "# Get the corresponding day and hour from X_new_original\n",
    "day = X_new_original.iloc[min_index]['day_of_week']\n",
    "hour = X_new_original.iloc[min_index]['hour_scrap']\n",
    "\n",
    "print(f'The lowest predicted ticket price is on {day} at hour {hour}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error: 289006.17\n",
      "Coefficient of determination: 0.04\n"
     ]
    }
   ],
   "source": [
    "# Calculate the mean squared error\n",
    "mse = mean_squared_error(y, predictions)\n",
    "print(f'Mean squared error: {mse:.2f}')\n",
    "\n",
    "# Calculate the coefficient of determination\n",
    "r2 = r2_score(y, predictions)\n",
    "print(f'Coefficient of determination: {r2:.2f}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict Lowest Price"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the first model above (cfr. Linear Regerssion: 2. The clean version), in this section, we try to predict the lowest price."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Which price will be the predicted lowest for particular day of the week ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "new = df[['tot_duration_seconds','ticket_price', 'hour_scrap','day_of_week','airline_company_dummy', 'destination_dummy','out_dep_time_dummy', 'in_arr_time_dummy']]\n",
    "# One-hot encode the day_of_week column\n",
    "df_encoded = pd.get_dummies(new, columns=['day_of_week'])\n",
    "\n",
    "# Select the independent and dependent variables\n",
    "X = df_encoded.drop('ticket_price', axis=1)\n",
    "y = df_encoded['ticket_price']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model1 = model\n",
    "model1.fit(X_train, y_train)\n",
    "\n",
    "# Calculate the training error\n",
    "y_train_pred = model1.predict(X_train)\n",
    "train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "train_rmse = np.sqrt(train_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monday: 946.2759570339065\n",
      "Tuesday: 960.6496240592078\n",
      "Wednesday: 975.7505906999343\n",
      "Thursday: 976.7169961236025\n",
      "Friday: 1022.2355305821748\n",
      "Saturday: 885.5741891942937\n",
      "Sunday: 860.6258062464815\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create a new data frame with all features set to their average or median values\n",
    "new_df = pd.DataFrame(columns=X.columns)\n",
    "for col in X.columns:\n",
    "    if col.startswith('day_of_week'):\n",
    "        new_df[col] = [0]\n",
    "    else:\n",
    "        new_df[col] = [X[col].median()]\n",
    "\n",
    "# Vary the day_of_week column to include each day of the week\n",
    "days = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "for day in days:\n",
    "    new_df[f'day_of_week_{day}'] = [1]\n",
    "    pred = model1.predict(new_df)\n",
    "    print(f'{day}: {pred[0]}')\n",
    "    new_df[f'day_of_week_{day}'] = [0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Which will be the predicted lowest ticket price for each combination of destination, airline and day of the week ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Destination: 0, Airline: 0, Day: Monday: 2216.978051360234\n",
      "Destination: 0, Airline: 0, Day: Tuesday: 2231.351718385535\n",
      "Destination: 0, Airline: 0, Day: Wednesday: 2246.452685026262\n",
      "Destination: 0, Airline: 0, Day: Thursday: 2247.41909044993\n",
      "Destination: 0, Airline: 0, Day: Friday: 2292.9376249085026\n",
      "Destination: 0, Airline: 0, Day: Saturday: 2156.2762835206213\n",
      "Destination: 0, Airline: 0, Day: Sunday: 2131.327900572809\n",
      "Destination: 0, Airline: 1, Day: Monday: 2027.3124346562577\n",
      "Destination: 0, Airline: 1, Day: Tuesday: 2041.686101681559\n",
      "Destination: 0, Airline: 1, Day: Wednesday: 2056.7870683222854\n",
      "Destination: 0, Airline: 1, Day: Thursday: 2057.7534737459537\n",
      "Destination: 0, Airline: 1, Day: Friday: 2103.272008204526\n",
      "Destination: 0, Airline: 1, Day: Saturday: 1966.6106668166449\n",
      "Destination: 0, Airline: 1, Day: Sunday: 1941.6622838688327\n",
      "Destination: 1, Airline: 0, Day: Monday: 1135.941573737883\n",
      "Destination: 1, Airline: 0, Day: Tuesday: 1150.3152407631842\n",
      "Destination: 1, Airline: 0, Day: Wednesday: 1165.4162074039107\n",
      "Destination: 1, Airline: 0, Day: Thursday: 1166.382612827579\n",
      "Destination: 1, Airline: 0, Day: Friday: 1211.9011472861512\n",
      "Destination: 1, Airline: 0, Day: Saturday: 1075.23980589827\n",
      "Destination: 1, Airline: 0, Day: Sunday: 1050.291422950458\n",
      "Destination: 1, Airline: 1, Day: Monday: 946.2759570339065\n",
      "Destination: 1, Airline: 1, Day: Tuesday: 960.6496240592078\n",
      "Destination: 1, Airline: 1, Day: Wednesday: 975.7505906999343\n",
      "Destination: 1, Airline: 1, Day: Thursday: 976.7169961236025\n",
      "Destination: 1, Airline: 1, Day: Friday: 1022.2355305821748\n",
      "Destination: 1, Airline: 1, Day: Saturday: 885.5741891942937\n",
      "Destination: 1, Airline: 1, Day: Sunday: 860.6258062464815\n"
     ]
    }
   ],
   "source": [
    "# Create a new data frame with all features set to their average or median values\n",
    "new_df = pd.DataFrame(columns=X.columns)\n",
    "for col in X.columns:\n",
    "    if col.startswith('day_of_week') or col == 'destination_dummy' or col == 'airline_company_dummy':\n",
    "        new_df[col] = [0]\n",
    "    else:\n",
    "        new_df[col] = [X[col].median()]\n",
    "\n",
    "# Vary the day_of_week, destination_dummy and airline_company_dummy columns\n",
    "days = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "for dest in [0, 1]:\n",
    "    new_df['destination_dummy'] = [dest]\n",
    "    for airline in [0, 1]:\n",
    "        new_df['airline_company_dummy'] = [airline]\n",
    "        for day in days:\n",
    "            new_df[f'day_of_week_{day}'] = [1]\n",
    "            pred = model1.predict(new_df)\n",
    "            print(f'Destination: {dest}, Airline: {airline}, Day: {day}: {pred[0]}')\n",
    "            new_df[f'day_of_week_{day}'] = [0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Which will be the prdicted lowest price for a given destination and a particular day of the week (as inputs) ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For destination 1 and day Monday, the lowest predicted ticket price is 946.2759570339065 with airline 1\n"
     ]
    }
   ],
   "source": [
    "def predict_lowest_price(destination, day):\n",
    "    # Create a new data frame with all features set to their average or median values\n",
    "    new_df = pd.DataFrame(columns=X.columns)\n",
    "    for col in X.columns:\n",
    "        if col.startswith('day_of_week') or col == 'destination_dummy' or col == 'airline_company_dummy':\n",
    "            new_df[col] = [0]\n",
    "        else:\n",
    "            new_df[col] = [X[col].median()]\n",
    "\n",
    "    # Set the destination_dummy and day_of_week columns to the given values\n",
    "    new_df['destination_dummy'] = [destination]\n",
    "    new_df[f'day_of_week_{day}'] = [1]\n",
    "\n",
    "    # Vary the airline_company_dummy column\n",
    "    min_price = float('inf')\n",
    "    best_airline = None\n",
    "    for airline in [0, 1]:\n",
    "        new_df['airline_company_dummy'] = [airline]\n",
    "        pred = model1.predict(new_df)\n",
    "        if pred[0] < min_price:\n",
    "            min_price = pred[0]\n",
    "            best_airline = airline\n",
    "\n",
    "    return min_price, best_airline\n",
    "\n",
    "# Example usage:\n",
    "destination = 1\n",
    "day = 'Monday'\n",
    "min_price, best_airline = predict_lowest_price(destination, day)\n",
    "print(f'For destination {destination} and day {day}, the lowest predicted ticket price is {min_price} with airline {best_airline}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Which will be the predicted the predicted lowest price and the best hour of the day to buy the ticket given a particular destination and day ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For destination 1 and day Monday, the lowest predicted ticket price is 929.4345891628188 with airline 1 at hour 8\n"
     ]
    }
   ],
   "source": [
    "def predict_lowest_price(destination, day):\n",
    "    # Create a new data frame with all features set to their average or median values\n",
    "    new_df = pd.DataFrame(columns=X.columns)\n",
    "    for col in X.columns:\n",
    "        if col.startswith('day_of_week') or col == 'destination_dummy' or col == 'airline_company_dummy' or col == 'hour_scrap':\n",
    "            new_df[col] = [0]\n",
    "        else:\n",
    "            new_df[col] = [X[col].median()]\n",
    "\n",
    "    # Set the destination_dummy and day_of_week columns to the given values\n",
    "    new_df['destination_dummy'] = [destination]\n",
    "    new_df[f'day_of_week_{day}'] = [1]\n",
    "\n",
    "    # Vary the hour_scrap and airline_company_dummy columns\n",
    "    min_price = float('inf')\n",
    "    best_airline = None\n",
    "    best_hour = None\n",
    "    for hour in [8, 10, 12, 14, 16, 18, 20, 22]:\n",
    "        new_df['hour_scrap'] = [hour]\n",
    "        for airline in [0, 1]:\n",
    "            new_df['airline_company_dummy'] = [airline]\n",
    "            pred = model1.predict(new_df)\n",
    "            if pred[0] < min_price:\n",
    "                min_price = pred[0]\n",
    "                best_airline = airline\n",
    "                best_hour = hour\n",
    "\n",
    "    return min_price, best_airline, best_hour\n",
    "\n",
    "# Example usage:\n",
    "destination = 1\n",
    "day = 'Monday'\n",
    "min_price, best_airline, best_hour = predict_lowest_price(destination, day)\n",
    "print(f'For destination {destination} and day {day}, the lowest predicted ticket price is {min_price} with airline {best_airline} at hour {best_hour}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create and fit the model using the training data\n",
    "# # Model 2\n",
    "# model2 = Lasso(alpha=1.0)\n",
    "# model2.fit(X_train, y_train)\n",
    "\n",
    "# # make predictions on the test data\n",
    "# y_pred = model2.predict(X_test)\n",
    "\n",
    "# # calculate the mean squared error of the predictions\n",
    "# mse = mean_squared_error(y_test, y_pred)\n",
    "# rmse = np.sqrt(mse)\n",
    "\n",
    "# print(f'Root Mean Squared Error: {rmse:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create and fit the model using the training data\n",
    "# # Model 3\n",
    "# model3 = LassoCV(cv=5)\n",
    "# model3.fit(X_train, y_train)\n",
    "\n",
    "# # print the best alpha value found by cross-validation\n",
    "# print(f'Best alpha: {model3.alpha_:.2f}')\n",
    "\n",
    "# # make predictions on the test data\n",
    "# y_pred = model3.predict(X_test)\n",
    "\n",
    "# # calculate the mean squared error of the predictions\n",
    "# mse = mean_squared_error(y_test, y_pred)\n",
    "# rmse = np.sqrt(mse)\n",
    "\n",
    "# print(f'Root Mean Squared Error: {rmse:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create and fit the model using the training data\n",
    "# # Model 4\n",
    "# model4 = Ridge(alpha=5.0)\n",
    "# model4.fit(X_train, y_train)\n",
    "\n",
    "# # make predictions on the test data\n",
    "# y_pred = model4.predict(X_test)\n",
    "\n",
    "# # calculate the mean squared error of the predictions\n",
    "# mse = mean_squared_error(y_test, y_pred)\n",
    "# rmse = np.sqrt(mse)\n",
    "\n",
    "# print(f'Root Mean Squared Error: {rmse:.2f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
